from pathlib import Path
from typing import Union

import numpy as np
import pytorch_lightning as pl
import torch
import torchmetrics
import wandb
from torch import nn

from . import inspect_code


class SaveOutput:
    """Class to save in the forward hook"""

    def __init__(self):
        self.outputs = []

    def __call__(self, module, module_in, module_out):
        self.outputs.append(module_out)

    def clear(self):
        self.outputs = []


class ScriptCheckpoint(pl.callbacks.Callback):
    """Script checkpoint. This saves the code of different snippets:
    * the model
    * the data module used in the Trainer
    * the encoder / decoder if the model has such attributes
    * the generator / discriminator if the model has such attributes
    """

    def __init__(self, dirpath: Path):
        """Constructor

        Args:
            dirpath (Path): path to save the snippets
        """
        super().__init__()
        self.dirpath = dirpath
        Path(self.dirpath).mkdir(parents=True, exist_ok=True)

    def on_fit_start(self, trainer: "pl.Trainer", pl_module: "pl.LightningModule"):
        """Saves the snippets at the beginning of the training.

        Args:
            trainer (pl.Trainer): trainer of `pytorch lightning`
            pl_module (pl.LightningModule): `pytorch lightning` module (which is often the model itself)
        """
        super().on_fit_start(trainer, pl_module)

        filename_model = Path(self.dirpath) / "model_script.txt"
        with open(filename_model, "w") as file:
            file.write(inspect_code.get_class_code(type(pl_module)))
        filename_datamodule = Path(self.dirpath) / "datamodule_script.txt"
        with open(filename_datamodule, "w") as file:
            file.write(inspect_code.get_class_code(type(trainer.datamodule)))

        for attr in ["generator", "discriminator", "encoder", "decoder"]:
            if hasattr(pl_module, attr):
                filename_model = Path(self.dirpath) / f"{attr}_script.txt"
                with open(filename_model, "w") as file:
                    file.write(
                        inspect_code.get_class_code(type(getattr(pl_module, attr)))
                    )


class AutoencoderGeneratedImagesCallback(pl.callbacks.Callback):
    """Callback to log images generated by an autoencoder model."""

    def __init__(
        self, images: Union[torch.Tensor, np.ndarray], log_every_n_epochs: int = 10
    ):
        """Constructor

        Args:
            images (Union[torch.Tensor, np.ndarray]): images to encode and decode.
            log_every_n_epochs (int, optional): frequence of the log. Defaults to 10.
        """
        super().__init__()
        self.images = images
        self.log_every_n_epochs = log_every_n_epochs
        self.current_epoch = 0

    def on_train_epoch_start(self, trainer, pl_module):
        """Encode and decode `self.images` at the beginning of each epoch.

        Args:
            trainer (_type_): _description_
            pl_module (_type_): _description_
        """
        if self.current_epoch == 0:
            image = wandb.Image(
                self.images,
                caption="Target batch",
            )
            trainer.logger.experiment.log({"generated_images": image})
        if self.current_epoch % self.log_every_n_epochs == 0:
            sample_imgs = pl_module(self.images)
            image = wandb.Image(
                sample_imgs,
                caption=f"First batch generated at epoch {self.current_epoch}",
            )
            trainer.logger.experiment.log({"generated_images": image})
        self.current_epoch += 1


class GeneratedImagesCallback(pl.callbacks.Callback):
    def __init__(self, descriptors, log_every_n_epochs=10):
        super().__init__()
        self.descriptors = descriptors
        self.log_every_n_epochs = log_every_n_epochs
        self.current_epoch = 0

    def on_train_epoch_start(self, trainer, pl_module):
        if self.current_epoch % self.log_every_n_epochs == 0:
            sample_imgs = pl_module(self.descriptors)
            image = wandb.Image(
                sample_imgs,
                caption=f"First batch generated at epoch {self.current_epoch}",
            )
            trainer.logger.experiment.log({"generated_images": image})
        self.current_epoch += 1


def metrics_str(
    predictions: Union[torch.Tensor, np.ndarray],
    targets: Union[torch.Tensor, np.ndarray],
) -> str:
    predictions = torch.FloatTensor(predictions)
    targets = torch.FloatTensor(targets)
    metrics_str = ""
    metrics_str += f"COSINE SIMILARITY: {torchmetrics.CosineSimilarity(reduction='mean')(predictions, targets)}\n"

    metrics_str += f"R2 SCORE: {torchmetrics.R2Score(num_outputs=predictions.shape[1])(predictions, targets)}\n"
    metrics_str += f"SMAPE: {torchmetrics.SymmetricMeanAbsolutePercentageError()(predictions, targets)}\n"

    metrics_str += (
        f"MAPE: {torchmetrics.MeanAbsolutePercentageError()(predictions, targets)}\n"
    )
    metrics_str += f"MAE: {torchmetrics.MeanAbsoluteError()(predictions, targets)}\n"
    metrics_str += f"MSE: {torchmetrics.MeanSquaredError()(predictions, targets)}\n"
    metrics_str += f"LOSS: {nn.L1Loss()(predictions, targets)}\n"
    metrics_str += "_______________________________________________________________"
    return metrics_str
