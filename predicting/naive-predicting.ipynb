{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Simple CNN network\n","\n","The original problem is:\n","\n","    (P) Compute the fabrics from multiple sliced images per rev\n","\n","We are firstly having an intermediate objective:\n","\n","    (P') Compute the fabrics from one single sliced images per rev\n","\n","Of course, the accuracy will be much worse because the fabrics are computed in every direction. However, it is a good try."]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-02-18T18:22:35.71475Z","iopub.status.busy":"2022-02-18T18:22:35.714432Z","iopub.status.idle":"2022-02-18T18:22:35.719176Z","shell.execute_reply":"2022-02-18T18:22:35.718188Z","shell.execute_reply.started":"2022-02-18T18:22:35.714718Z"}},"source":["# Importing the dataframe\n","\n","Firstly, we initialize wandb. It is a tool that allows to store the losses and retrieve the deframe. Otherwise, you can directly access locally the dataframe on your computer."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install wandb --upgrade"]},{"cell_type":"markdown","metadata":{},"source":["We import all the useful packages."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","IS_COLAB = \"google.colab\" in sys.modules\n","IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n","if IS_KAGGLE:\n","    repo_path = Path(\"../input/microstructure-reconstruction\")\n","elif IS_COLAB:\n","    from google.colab import drive\n","\n","    drive.mount(\"/content/gdrive\")\n","    repo_path = Path(\"/content/gdrive/MyDrive/microstructure-reconstruction\")\n","else:\n","    repo_path = Path(\"/home/matias/microstructure-reconstruction\")\n","sys.path.append(str(repo_path))\n","\n","from copy import deepcopy\n","from importlib import reload\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from PIL import Image\n","import pandas as pd\n","import pytorch_lightning as pl\n","import torch\n","from typing import Union, List\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchmetrics\n","import torchvision.models as pretrained_models\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KernelDensity\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import DataLoader\n","from torchvision import transforms, utils\n","from tqdm import tqdm\n","\n","import wandb\n","from custom_datasets import dataset\n","from custom_models import models\n","from tools import dataframe_reformat, inspect_code, plotting, training, wandb_api\n","\n","log_wandb = True\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","kwargs = {\"num_workers\": 2, \"pin_memory\": True} if use_cuda else {\"num_workers\": 4}\n","print(f\"[INFO]: Computation device: {device}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["We initialize a wandb run, that will save our metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if log_wandb:\n","    import wandb\n","    wandb_api.login()\n","    run = wandb.init(\n","        project=\"microstructure-reconstruction\",\n","        group=\"Naive Network\",\n","        job_type=\"test\",\n","    )\n"]},{"cell_type":"markdown","metadata":{},"source":["Parameters of our run:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if log_wandb:\n","    config = wandb.config\n","else:\n","    config = wandb_api.Config()\n","\n","config[\"job_type\"] = run.job_type\n","config[\"train_val_split\"] = 0.7\n","config[\"seed\"] = 42\n","config[\"batch_size\"] = 32\n","config[\"learning_rate\"] = 0.0003\n","config[\"device\"] = device\n","config[\"momentum\"] = 0.7\n","config[\"architecture\"] = \"VGG\"\n","config[\"input_width\"] = 100\n","config[\"weight_decay\"] = 0.00005\n","config[\"epochs\"] = 0\n","config[\"frac_sample\"] = 1\n","config[\"frac_noise\"] = 0.9\n","config[\"log_wandb\"] = log_wandb\n","torch.manual_seed(config[\"seed\"])\n","pl.seed_everything(config[\"seed\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class DataModule(pl.LightningDataModule):\n","    def __init__(\n","        self,\n","        config,\n","        repo_path,\n","        train_df=None,\n","        test_df=None,\n","    ):\n","        super().__init__()\n","        self.config = config\n","        self.repo_path = repo_path\n","        self.train_df = train_df.convert_dtypes() if train_df is not None else None\n","        self.test_df = test_df.convert_dtypes() if test_df is not None else None\n","\n","        if self.config[\"log_wandb\"]:\n","            if self.train_df is None:\n","                self.training_data_at = wandb.Api().artifact(\n","                    \"matiasetcheverry/microstructure-reconstruction/train_df:10_images\"\n","                )\n","            if self.test_df is None:\n","                self.test_data_at = wandb.Api().artifact(\n","                    \"matiasetcheverry/microstructure-reconstruction/test_df:10_images\"\n","                )\n","\n","        self.transform = transforms.Compose(\n","            [\n","                transforms.CenterCrop(207),\n","                transforms.Resize(\n","                    (self.config[\"input_width\"], self.config[\"input_width\"])\n","                ),\n","                transforms.ToTensor(),\n","                transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n","            ]\n","        )\n","\n","    def prepare_data(self):\n","        if self.config[\"log_wandb\"]:\n","            if self.train_df is None:\n","                self.training_data_at.download()\n","            if self.test_df is None:\n","                self.test_data_at.download()\n","\n","    def _init_df_wandb(self):\n","        if self.train_df is None:\n","            self.train_df = wandb_api.convert_table_to_dataframe(\n","                self.training_data_at.get(\"fabrics\")\n","            )\n","            self.train_df[\"photos\"] = self.train_df[\"photos\"].apply(\n","                func=lambda photo_paths: [\n","                    str(self.repo_path / Path(x)) for x in photo_paths\n","                ]\n","            )\n","        if self.test_df is None:\n","            self.test_df = wandb_api.convert_table_to_dataframe(\n","                self.test_data_at.get(\"fabrics\")\n","            )\n","            self.test_df[\"photos\"] = self.test_df[\"photos\"].apply(\n","                func=lambda photo_paths: [\n","                    str(self.repo_path / Path(x)) for x in photo_paths\n","                ]\n","            )\n","\n","    def _init_df_local(self):\n","        fabrics_df = pd.read_csv(self.repo_path / \"REV1_600/fabrics.txt\")\n","        path_to_slices = self.repo_path / \"REV1_600/REV1_600Slices\"\n","        fabrics_df[\"photos\"] = fabrics_df[\"id\"].apply(\n","            func=dataframe_reformat.associate_rev_id_to_its_images,\n","            args=(path_to_slices, 10),\n","        )\n","        fabrics_df = fabrics_df[fabrics_df.photos.str.len().gt(0)]\n","        fabrics_df[\"photos\"] = fabrics_df[\"photos\"].apply(func=lambda x: sorted(x))\n","        train_df, test_df = train_test_split(\n","            fabrics_df,\n","            train_size=config[\"train_val_split\"],\n","            random_state=config[\"seed\"],\n","            shuffle=True,\n","        )\n","        if self.train_df is None:\n","            self.train_df = train_df.reset_index(drop=True)\n","        if self.test_df is None:\n","            self.test_df = test_df.reset_index(drop=True)\n","\n","    def init_df(self):\n","        if self.config[\"log_wandb\"]:\n","            self._init_df_wandb()\n","        else:\n","            self._init_df_local()\n","\n","    def setup(self, stage):\n","        self.init_df()\n","        self.scaler = MinMaxScaler(feature_range=(0, 1))\n","        self.scaler.fit_transform(self.train_df.iloc[:, 1:-1])\n","        self.scaler.transform(self.test_df.iloc[:, 1:-1])\n","        normalized_train_df = deepcopy(self.train_df)\n","        normalized_train_df.iloc[:, 1:-1] = self.scaler.transform(\n","            self.train_df.iloc[:, 1:-1]\n","        )\n","        normalized_test_df = deepcopy(self.test_df)\n","        normalized_test_df.iloc[:, 1:-1] = self.scaler.transform(\n","            self.test_df.iloc[:, 1:-1]\n","        )\n","        self.kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.75).fit(\n","            normalized_train_df.iloc[:, 1:-1].to_numpy()\n","        )\n","\n","        self.train_dataset = dataset.SinglePhotoDataset(\n","            normalized_train_df, transform=self.transform, noise=config[\"frac_noise\"]\n","        )\n","        self.validation_dataset = dataset.SinglePhotoDataset(\n","            normalized_test_df, transform=self.transform, noise=0\n","        )\n","        self.targets = self.test_df.iloc[:, 1:-1].to_numpy()\n","\n","        \n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.config[\"batch_size\"],\n","            shuffle=True,\n","            **kwargs,\n","        )\n","\n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.validation_dataset,\n","            batch_size=self.config[\"batch_size\"],\n","            shuffle=False,\n","            **kwargs,\n","        )\n","\n","    def test_dataloader(self):\n","        return self.val_dataloader()\n","\n","    def predict_dataloader(self):\n","        return DataLoader(\n","            [image for image, _ in self.validation_dataset],\n","            batch_size=self.config[\"batch_size\"],\n","            shuffle=False,\n","            **kwargs,\n","        )\n","\n","\n","dm = DataModule(config, repo_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dm.prepare_data()\n","dm.setup(stage=\"fit\")\n","first_batch = next(iter(dm.train_dataloader()))\n","\n","images, labels = first_batch[0], first_batch[1]\n","grid = utils.make_grid(images)\n","fig = plt.figure(figsize=(40, 10))\n","plt.imshow(grid.numpy().transpose((1, 2, 0)))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class VGG11(models.BaseModel):\n","    def __init__(self, config, kde = None, scaler=None):\n","        super().__init__(config)\n","\n","        self.config = config\n","        self.config[\"model_type\"] = type(self)\n","        self.kde = kde\n","        self.scaler = scaler\n","\n","        self.configure_model()\n","        self.configure_criterion()\n","        self.configure_metrics()\n","        \n","    def configure_model(self):\n","        layers = np.array([64, 128, 256, 512]) // 4\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(1, layers[0], kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(layers[0], layers[1], kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(layers[1], layers[2], kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(layers[2], layers[2], kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(layers[2], layers[3], kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(layers[3], layers[3], kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(layers[3], layers[3], kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(layers[3], layers[3], kernel_size=3, padding=1),\n","            nn.BatchNorm2d(layers[3]),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","#             nn.MaxPool2d(kernel_size=int(self.config[\"input_width\"] / (2 ** 4)), stride=int(self.config[\"input_width\"] / (2 ** 4))),\n","        )\n","        input_fc = int((self.config[\"input_width\"] / (2 ** 5)) ** 2 * layers[3])\n","        # fully connected linear layers\n","        n = 256\n","        self.linear_layers = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features=input_fc, out_features=n),\n","            nn.ReLU(),\n","            nn.Dropout2d(0.3),\n","            nn.Linear(in_features=n, out_features=1),\n","            nn.ReLU(),\n","            nn.Dropout2d(0.3),\n","            nn.Linear(in_features=n, out_features=1),\n","        )\n","    \n","    def forward(self, x):\n","        x = self.conv_layers(x)\n","        # flatten to prepare for the fully connected layers\n","#         x = x.view(x.size(0), -1)\n","        x = self.linear_layers(x)\n","        return x\n","    \n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self(x)\n","#         weights = self.kde.score_samples(y_hat.cpu().detach().numpy())\n","        loss = self.criterion(y_hat, y)\n","        self.log(\n","            \"train_loss\",\n","            loss,\n","            on_step=False,\n","            on_epoch=True,\n","        )\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self(x)\n","#         weights = self.kde.score_samples(y_hat.cpu().detach().numpy())\n","        metrics = {name: metric(y, y_hat) for name, metric in self.metrics.items()}\n","        metrics[\"val_loss\"] = self.criterion(y_hat, y)\n","        self.log_dict(metrics, on_step=False, on_epoch=True, prog_bar=True)\n","        return metrics\n","\n","    def configure_criterion(self):\n","        self.criterion = self.L1Loss\n","        self.config[\"loss_type\"] = type(self.criterion)\n","\n","    def L1Loss(self, y, y_hat, weights=None):\n","        if weights is not None:\n","            weights = nn.functional.normalize(weights, p=1, dim=0)\n","            return torch.mean(torch.matmul(weights, torch.abs(y - y_hat)))\n","        else: \n","            return torch.mean(torch.abs(y - y_hat))\n","\n","    def configure_metrics(self):\n","        self.metrics = {\n","            \"mae\": torchmetrics.MeanAbsoluteError().to(self.config[\"device\"]),\n","            \"mape\": torchmetrics.MeanAbsolutePercentageError().to(\n","                self.config[\"device\"]\n","            ),\n","            \"smape\": torchmetrics.SymmetricMeanAbsolutePercentageError().to(\n","                self.config[\"device\"]\n","            ),\n","            \"r2_score\": torchmetrics.R2Score(num_outputs=23).to(self.config[\"device\"]),\n","            \"cosine_similarity\": torchmetrics.CosineSimilarity(reduction=\"mean\").to(\n","                self.config[\"device\"]\n","            ),\n","        }\n","        \n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(\n","            self.parameters(),\n","            lr=self.config[\"learning_rate\"],\n","            weight_decay=self.config[\"weight_decay\"],\n","        )\n","        self.config[\"optimizer_type\"] = type(optimizer)\n","        return optimizer\n","\n","\n","model = VGG11(config, kde=dm.kde)\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"[INFO]: {total_params:,} total parameters.\")\n","model(torch.rand((2, 1, config[\"input_width\"], config[\"input_width\"])))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(\n","    dirpath=run.dir,\n","    filename=\"{epoch}-{val_loss:.3f}\",\n","    monitor=\"val_loss\",\n","    mode=\"min\",\n","    verbose=True,\n","    save_last=True,\n",")\n","\n","script_checkpoint = training.ScriptCheckpoint(\n","    dirpath=run.dir,\n",")\n","\n","callbacks = [script_checkpoint]\n","log = None\n","if run.job_type == \"train\" or True:\n","    callbacks.append(model_checkpoint)\n","    print(f\"[INFO]: saving models.\")\n","if run.job_type == \"debug\":\n","    log = \"all\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if config[\"log_wandb\"]:\n","    wandb_logger = pl.loggers.WandbLogger()\n","    wandb_logger.watch(model, log=log, log_graph=True)\n","else:\n","    wandb_logger = None\n","trainer = pl.Trainer(\n","    max_epochs=150,\n","    callbacks=callbacks,\n","    logger=wandb_logger,\n","    devices=\"auto\", \n","    accelerator=\"auto\",\n","#     limit_train_batches=0.3, \n","#     limit_val_batches=0.3,\n","#     log_every_n_steps=1\n",")\n","trainer.fit(model, datamodule=dm, )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dm.prepare_data()\n","dm.setup(\"validate\")\n","predictions = torch.cat(trainer.predict(model, dataloaders=dm.predict_dataloader()))\n","targets = torch.FloatTensor(dm.targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["save_output = training.SaveOutput()\n","handle = model.conv_layers[3].register_forward_hook(save_output)\n","image = images[0]\n","model(image.unsqueeze(0))\n","handle.remove()\n","outputs = save_output.outputs[0].permute(1, 0, 2, 3).detach().cpu()[:30]\n","grid_img = utils.make_grid(outputs, normalize=True, pad_value=1, padding=1)\n","plt.figure(figsize=(30, 30))\n","plt.imshow(grid_img.permute(1, 2, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import seaborn as sns\n","\n","fig, ax = plt.subplots()\n","sns.kdeplot(\n","    data=dm.scaler.transform(targets.cpu().numpy())[:, 4],\n","    color=\"orange\",\n","    ax=ax,\n","    label=\"target\",\n",")\n","sns.kdeplot(\n","    data=predictions.cpu().numpy(),\n","    shade=True,\n","    color=\"orange\",\n","    ax=ax,\n","    label=\"predictions\",\n",")\n","ax.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["run.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for noise in [0.9, 0.3, 0]:\n","    for layer_divider in [4, 16]:\n","        for fc_divider in [4, 16]:\n","            for dropout in [0.2, 0.6]:\n","                if log_wandb:\n","                    import wandb\n","                    wandb_api.login()\n","                    run = wandb.init(\n","                        project=\"microstructure-reconstruction\",\n","                        group=\"Naive Network\",\n","                        job_type=\"test\",\n","                    )\n","\n","                if log_wandb:\n","                    config = wandb.config\n","                else:\n","                    config = wandb_api.Config()\n","\n","                config[\"job_type\"] = run.job_type\n","                config[\"train_val_split\"] = 0.7\n","                config[\"seed\"] = 42\n","                config[\"batch_size\"] = 32\n","                config[\"learning_rate\"] = 0.00006\n","                config[\"device\"] = device\n","                config[\"momentum\"] = 0.9\n","                config[\"architecture\"] = \"VGG\"\n","                config[\"input_width\"] = 64\n","                config[\"weight_decay\"] = 0.005\n","                config[\"epochs\"] = 0\n","                config[\"frac_sample\"] = 1\n","                config[\"frac_noise\"] = noise\n","                # config[\"total_layers\"] = 24\n","                # config[\"fixed_layers\"] = 0\n","                config[\"log_wandb\"] = log_wandb\n","                torch.manual_seed(config[\"seed\"])\n","                pl.seed_everything(config[\"seed\"])\n","\n","                class VGG11(models.BaseModel):\n","                    def __init__(self, config, kde = None, scaler=None):\n","                        super().__init__(config)\n","\n","                        self.config = config\n","                        self.config[\"model_type\"] = type(self)\n","                        self.kde = kde\n","                        self.scaler = scaler\n","\n","                        self.configure_model()\n","                        self.configure_criterion()\n","                        self.configure_metrics()\n","\n","                    def configure_model(self):\n","                        layers = np.array([64, 128, 256, 512]) // layer_divider\n","                        self.conv_layers = nn.Sequential(\n","                            nn.Conv2d(1, layers[0], kernel_size=3, padding=1),\n","                            nn.ReLU(),\n","                            nn.MaxPool2d(kernel_size=2, stride=2),\n","                            nn.Conv2d(layers[0], layers[1], kernel_size=3, padding=1),\n","                            nn.ReLU(),\n","                            nn.MaxPool2d(kernel_size=2, stride=2),\n","                            nn.Conv2d(layers[1], layers[2], kernel_size=3, padding=1),\n","                            nn.ReLU(),\n","                            nn.Conv2d(layers[2], layers[2], kernel_size=3, padding=1),\n","                            nn.ReLU(),\n","                            nn.MaxPool2d(kernel_size=2, stride=2),\n","                            nn.Conv2d(layers[2], layers[3], kernel_size=3, padding=1),\n","                            nn.ReLU(),\n","                            nn.Conv2d(layers[3], layers[3], kernel_size=3, padding=1),\n","                            nn.ReLU(),\n","                            nn.MaxPool2d(kernel_size=2, stride=2),\n","                            nn.Conv2d(layers[3], layers[3], kernel_size=3, padding=1),\n","                            nn.ReLU(),\n","                            nn.Conv2d(layers[3], layers[3], kernel_size=3, padding=1),\n","                            nn.BatchNorm2d(layers[3]),\n","                            nn.ReLU(),\n","                            nn.MaxPool2d(kernel_size=2, stride=2)\n","                #             nn.MaxPool2d(kernel_size=int(self.config[\"input_width\"] / (2 ** 4)), stride=int(self.config[\"input_width\"] / (2 ** 4))),\n","                        )\n","                        input_fc = int((self.config[\"input_width\"] / (2 ** 5)) ** 2 * layers[3])\n","                        # fully connected linear layers\n","                        n = 256 // fc_divider\n","                        self.linear_layers = nn.Sequential(\n","                            nn.Flatten(),\n","                            nn.Linear(in_features=input_fc, out_features=n),\n","                            nn.ReLU(),\n","                            nn.Dropout2d(dropout),\n","                            nn.Linear(in_features=n, out_features=1),\n","                #             nn.ReLU(),\n","                #             nn.Dropout2d(0.3),\n","                #             nn.Linear(in_features=n, out_features=1),\n","                        )\n","\n","                    def forward(self, x):\n","                        x = self.conv_layers(x)\n","                        # flatten to prepare for the fully connected layers\n","                #         x = x.view(x.size(0), -1)\n","                        x = self.linear_layers(x)\n","                        return x\n","\n","                    def training_step(self, batch, batch_idx):\n","                        x, y = batch\n","                        y_hat = self(x)\n","                #         weights = self.kde.score_samples(y_hat.cpu().detach().numpy())\n","                        loss = self.criterion(y_hat, y)\n","                        self.log(\n","                            \"train_loss\",\n","                            loss,\n","                            on_step=False,\n","                            on_epoch=True,\n","                        )\n","                        return loss\n","\n","                    def validation_step(self, batch, batch_idx):\n","                        x, y = batch\n","                        y_hat = self(x)\n","                #         weights = self.kde.score_samples(y_hat.cpu().detach().numpy())\n","                        metrics = {name: metric(y, y_hat) for name, metric in self.metrics.items()}\n","                        metrics[\"val_loss\"] = self.criterion(y_hat, y)\n","                        self.log_dict(metrics, on_step=False, on_epoch=True, prog_bar=True)\n","                        return metrics\n","\n","                    def configure_criterion(self):\n","                        self.criterion = self.L1Loss\n","                        self.config[\"loss_type\"] = type(self.criterion)\n","\n","                    def L1Loss(self, y, y_hat, weights=None):\n","                        if weights is not None:\n","                            weights = nn.functional.normalize(weights, p=1, dim=0)\n","                            return torch.mean(torch.matmul(weights, torch.abs(y - y_hat)))\n","                        else: \n","                            return torch.mean(torch.abs(y - y_hat))\n","\n","                    def configure_metrics(self):\n","                        self.metrics = {\n","                            \"mae\": torchmetrics.MeanAbsoluteError().to(self.config[\"device\"]),\n","                            \"mape\": torchmetrics.MeanAbsolutePercentageError().to(\n","                                self.config[\"device\"]\n","                            ),\n","                            \"smape\": torchmetrics.SymmetricMeanAbsolutePercentageError().to(\n","                                self.config[\"device\"]\n","                            ),\n","                            \"r2_score\": torchmetrics.R2Score(num_outputs=23).to(self.config[\"device\"]),\n","                            \"cosine_similarity\": torchmetrics.CosineSimilarity(reduction=\"mean\").to(\n","                                self.config[\"device\"]\n","                            ),\n","                        }\n","\n","                    def configure_optimizers(self):\n","                        optimizer = torch.optim.Adam(\n","                            self.parameters(),\n","                            lr=self.config[\"learning_rate\"],\n","                            weight_decay=self.config[\"weight_decay\"],\n","                        )\n","                        self.config[\"optimizer_type\"] = type(optimizer)\n","                        return optimizer\n","\n","                dm = DataModule(config, repo_path)\n","\n","                model = VGG11(config, kde=None)\n","                total_params = sum(p.numel() for p in model.parameters())\n","                print(f\"NOISE {noise}\\tFC DIVIDER {fc_divider}\\tLAYER DIVIDER {layer_divider}\\tDROPOUT {dropout}\")\n","                print(f\"[INFO]: {total_params:,} total parameters.\")\n","                model(torch.rand((2, 1, config[\"input_width\"], config[\"input_width\"])))\n","\n","                model_checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(\n","                    dirpath=run.dir,\n","                    filename=\"{epoch}-{val_loss:.3f}\",\n","                    monitor=\"val_loss\",\n","                    mode=\"min\",\n","                    verbose=True,\n","                    save_last=True,\n","                )\n","\n","    #             script_checkpoint = training.ScriptCheckpoint(\n","    #                 dirpath=run.dir,\n","    #             )\n","\n","    #             callbacks = [script_checkpoint]\n","                callbacks = []\n","                log = None\n","                if run.job_type == \"train\" or True:\n","                    callbacks.append(model_checkpoint)\n","                    print(f\"[INFO]: saving models.\")\n","                if run.job_type == \"debug\":\n","                    log = \"all\"\n","\n","                if config[\"log_wandb\"]:\n","                    wandb_logger = pl.loggers.WandbLogger()\n","                    wandb_logger.watch(model, log=log, log_graph=True)\n","                else:\n","                    wandb_logger = None\n","                trainer = pl.Trainer(\n","                    max_epochs=30,\n","                    callbacks=callbacks,\n","                    logger=wandb_logger,\n","                    devices=\"auto\", \n","                    accelerator=\"auto\",\n","                #     limit_train_batches=0.3, \n","                #     limit_val_batches=0.3,\n","                #     log_every_n_steps=1\n","                )\n","                trainer.fit(model, datamodule=dm, )\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
