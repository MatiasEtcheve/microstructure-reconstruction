{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Network per channel\n","\n","As we dive more precisely into the topic, we now create a more robust dataset:\n","\n","* each input is an image of size `(C, W, H)`. On each channel, there is a grayscale sliced image. So, \n","  * the first `C/3` channels are sliced images along x axis\n","  * the following `C/3` channels are sliced images along x axis\n","  * the last `C/3` channels are sliced images along x axis\n","* each output is list of fabric descriptors\n","\n","If we take `C=3`, we can use a pretrained VGG model. Indeed, this model is trained on RGB images, which have 3 channels."]},{"cell_type":"markdown","metadata":{},"source":["# Importing the dataframe"]},{"cell_type":"markdown","metadata":{},"source":["Firstly, we initialize wandb. It is a tool that allows to store the losses and retrieve the deframe. Otherwise, you can directly access locally the dataframe on your computer."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:42:52.941434Z","iopub.status.busy":"2022-03-07T11:42:52.941159Z","iopub.status.idle":"2022-03-07T11:43:00.803747Z","shell.execute_reply":"2022-03-07T11:43:00.802907Z","shell.execute_reply.started":"2022-03-07T11:42:52.941398Z"},"executionInfo":{"elapsed":4758,"status":"ok","timestamp":1644495641039,"user":{"displayName":"Matias Etcheverry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAaRgyKc_t8sZam6khtkO8IvEB4xqvz8dwKcJh=s64","userId":"13887759295001408411"},"user_tz":-60},"id":"KCF0gEhbI9yg","outputId":"65a442db-4731-422d-a7a4-ae8f237f375d","trusted":true},"outputs":[],"source":["!pip install wandb --upgrade"]},{"cell_type":"markdown","metadata":{},"source":["We import all the useful packages."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:44:47.964139Z","iopub.status.busy":"2022-03-07T11:44:47.963870Z","iopub.status.idle":"2022-03-07T11:44:52.906207Z","shell.execute_reply":"2022-03-07T11:44:52.905336Z","shell.execute_reply.started":"2022-03-07T11:44:47.964110Z"},"executionInfo":{"elapsed":12323,"status":"ok","timestamp":1644495653358,"user":{"displayName":"Matias Etcheverry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAaRgyKc_t8sZam6khtkO8IvEB4xqvz8dwKcJh=s64","userId":"13887759295001408411"},"user_tz":-60},"id":"396f8318","outputId":"ecbf203b-7c9f-4285-a787-3c279f8be90f","trusted":true},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","IS_COLAB = \"google.colab\" in sys.modules\n","IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n","if IS_KAGGLE:\n","    repo_path = Path(\"../input/microstructure-reconstruction\")\n","elif IS_COLAB:\n","    from google.colab import drive\n","\n","    drive.mount(\"/content/gdrive\")\n","    repo_path = Path(\"/content/gdrive/MyDrive/microstructure-reconstruction\")\n","else:\n","    repo_path = Path(\"/home/matias/microstructure-reconstruction\")\n","sys.path.append(str(repo_path))\n","\n","from copy import deepcopy\n","from importlib import reload\n","from typing import List, Union\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pytorch_lightning as pl\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchmetrics\n","import torchvision.models as pretrained_models\n","import wandb\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KernelDensity\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import DataLoader\n","from torchvision import transforms, utils\n","from tqdm import tqdm\n","\n","from custom_datasets import dataset\n","from custom_models import models\n","from tools import dataframe_reformat, inspect_code, plotting, training, wandb_api\n","\n","log_wandb = True\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","kwargs = {\"num_workers\": 2, \"pin_memory\": True} if use_cuda else {\"num_workers\": 4}\n","print(f\"[INFO]: Computation device: {device}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["We initialize a wandb run, that will save our metrics"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:44:52.908408Z","iopub.status.busy":"2022-03-07T11:44:52.907963Z","iopub.status.idle":"2022-03-07T11:45:00.191681Z","shell.execute_reply":"2022-03-07T11:45:00.190994Z","shell.execute_reply.started":"2022-03-07T11:44:52.908370Z"},"executionInfo":{"elapsed":6825,"status":"ok","timestamp":1644495660175,"user":{"displayName":"Matias Etcheverry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAaRgyKc_t8sZam6khtkO8IvEB4xqvz8dwKcJh=s64","userId":"13887759295001408411"},"user_tz":-60},"id":"dj85A2mMIz_j","outputId":"91b1c0e2-dbca-4381-e5ac-9f404baf57db","trusted":true},"outputs":[],"source":["if log_wandb:\n","    import wandb\n","\n","    wandb_api.login()\n","    run = wandb.init(\n","        project=\"microstructure-reconstruction\",\n","        group=\"NChannel Network\",\n","        job_type=\"test\",\n","    )\n"]},{"cell_type":"markdown","metadata":{},"source":["Parameters of our run:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:45:00.193919Z","iopub.status.busy":"2022-03-07T11:45:00.193409Z","iopub.status.idle":"2022-03-07T11:45:00.217613Z","shell.execute_reply":"2022-03-07T11:45:00.216864Z","shell.execute_reply.started":"2022-03-07T11:45:00.193880Z"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644495660176,"user":{"displayName":"Matias Etcheverry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAaRgyKc_t8sZam6khtkO8IvEB4xqvz8dwKcJh=s64","userId":"13887759295001408411"},"user_tz":-60},"id":"w2Me9kwpIz_j","outputId":"f4290858-5c72-4331-ed8d-b99ffeb3b058","trusted":true},"outputs":[],"source":["if log_wandb:\n","    config = wandb.config\n","else:\n","    config = wandb_api.Config()\n","\n","config[\"job_type\"] = run.job_type\n","config[\"train_val_split\"] = 0.7\n","config[\"seed\"] = 42\n","config[\"batch_size\"] = 64\n","config[\"learning_rate\"] = 0.0001\n","config[\"device\"] = device\n","config[\"momentum\"] = 0.9\n","config[\"architecture\"] = \"pretrained VGG\"\n","config[\"input_width\"] = 64\n","config[\"weight_decay\"] = 0.00005\n","config[\"epochs\"] = 0\n","config[\"frac_sample\"] = 1\n","config[\"frac_noise\"] = 0\n","config[\"nb_image_per_axis\"] = 1\n","config[\"log_wandb\"] = log_wandb\n","torch.manual_seed(config[\"seed\"])\n","pl.seed_everything(config[\"seed\"])\n"]},{"cell_type":"markdown","metadata":{},"source":["We retrieve the dataframe containing the descriptors. This can locally be done on your computer."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:45:00.220289Z","iopub.status.busy":"2022-03-07T11:45:00.220036Z","iopub.status.idle":"2022-03-07T11:45:00.534785Z","shell.execute_reply":"2022-03-07T11:45:00.534086Z","shell.execute_reply.started":"2022-03-07T11:45:00.220253Z"},"executionInfo":{"elapsed":3755,"status":"ok","timestamp":1644495663926,"user":{"displayName":"Matias Etcheverry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAaRgyKc_t8sZam6khtkO8IvEB4xqvz8dwKcJh=s64","userId":"13887759295001408411"},"user_tz":-60},"id":"9397b6e5","trusted":true},"outputs":[],"source":["class DataModule(pl.LightningDataModule):\n","    def __init__(\n","        self,\n","        config,\n","        repo_path,\n","        train_df=None,\n","        test_df=None,\n","        train_dataset=None,\n","        validation_dataset=None,\n","    ):\n","        super().__init__()\n","        self.config = config\n","        self.repo_path = repo_path\n","        self.train_df = train_df.convert_dtypes() if train_df is not None else None\n","        self.test_df = test_df.convert_dtypes() if test_df is not None else None\n","        self.train_dataset = train_dataset\n","        self.validation_dataset = validation_dataset\n","\n","        if self.config[\"log_wandb\"]:\n","            if self.train_df is None:\n","                self.training_data_at = wandb.Api().artifact(\n","                    \"matiasetcheverry/microstructure-reconstruction/train_df:10_images\"\n","                )\n","            if self.test_df is None:\n","                self.test_data_at = wandb.Api().artifact(\n","                    \"matiasetcheverry/microstructure-reconstruction/test_df:10_images\"\n","                )\n","\n","        self.transform = transforms.Compose(\n","            [\n","                transforms.CenterCrop(207),\n","                transforms.Resize(\n","                    (self.config[\"input_width\"], self.config[\"input_width\"])\n","                ),\n","                transforms.ToTensor(),\n","                transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n","            ]\n","        )\n","\n","    def prepare_data(self):\n","        if self.config[\"log_wandb\"]:\n","            if self.train_df is None:\n","                self.training_data_at.download()\n","            if self.test_df is None:\n","                self.test_data_at.download()\n","\n","    def _init_df_wandb(self):\n","        if self.train_df is None:\n","            self.train_df = wandb_api.convert_table_to_dataframe(\n","                self.training_data_at.get(\"fabrics\")\n","            )\n","            self.train_df[\"photos\"] = self.train_df[\"photos\"].apply(\n","                func=lambda photo_paths: [\n","                    str(self.repo_path / Path(x)) for x in photo_paths\n","                ]\n","            )\n","        if self.test_df is None:\n","            self.test_df = wandb_api.convert_table_to_dataframe(\n","                self.test_data_at.get(\"fabrics\")\n","            )\n","            self.test_df[\"photos\"] = self.test_df[\"photos\"].apply(\n","                func=lambda photo_paths: [\n","                    str(self.repo_path / Path(x)) for x in photo_paths\n","                ]\n","            )\n","\n","    def _init_df_local(self):\n","        fabrics_df = pd.read_csv(self.repo_path / \"REV1_600/fabrics.txt\")\n","        path_to_slices = self.repo_path / \"REV1_600/REV1_600Slices\"\n","        fabrics_df[\"photos\"] = fabrics_df[\"id\"].apply(\n","            func=dataframe_reformat.associate_rev_id_to_its_images,\n","            args=(path_to_slices, 10),\n","        )\n","        fabrics_df = fabrics_df[fabrics_df.photos.str.len().gt(0)]\n","        fabrics_df[\"photos\"] = fabrics_df[\"photos\"].apply(func=lambda x: sorted(x))\n","        train_df, test_df = train_test_split(\n","            fabrics_df,\n","            train_size=config[\"train_val_split\"],\n","            random_state=config[\"seed\"],\n","            shuffle=True,\n","        )\n","        if self.train_df is None:\n","            self.train_df = train_df.reset_index(drop=True)\n","        if self.test_df is None:\n","            self.test_df = test_df.reset_index(drop=True)\n","\n","    def init_df(self):\n","        if self.config[\"log_wandb\"]:\n","            self._init_df_wandb()\n","        else:\n","            self._init_df_local()\n","\n","    def setup(self, stage):\n","        if self.train_dataset is None or self.validation_dataset is None:\n","            self.init_df()\n","            self.scaler = MinMaxScaler(feature_range=(0, 1))\n","            self.scaler.fit_transform(self.train_df.iloc[:, 1:-1])\n","            self.scaler.transform(self.test_df.iloc[:, 1:-1])\n","            normalized_train_df = deepcopy(self.train_df)\n","            normalized_train_df.iloc[:, 1:-1] = self.scaler.transform(\n","                self.train_df.iloc[:, 1:-1]\n","            )\n","            normalized_test_df = deepcopy(self.test_df)\n","            normalized_test_df.iloc[:, 1:-1] = self.scaler.transform(\n","                self.test_df.iloc[:, 1:-1]\n","            )\n","            self.kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.75).fit(\n","                normalized_train_df.iloc[:, 1:-1].to_numpy()\n","            )\n","            if self.train_dataset is None:\n","                self.train_dataset = dataset.NChannelPhotosDataset(\n","                    normalized_train_df,\n","                    nb_input_photos_per_plane=1,\n","                    transform=self.transform,\n","                    noise=config[\"frac_noise\"],\n","                )\n","            if self.validation_dataset is None:\n","                self.validation_dataset = dataset.NChannelPhotosDataset(\n","                    normalized_test_df,\n","                    nb_input_photos_per_plane=1,\n","                    transform=self.transform,\n","                    noise=0,\n","                )\n","            self.targets = self.test_df.iloc[:, 1:-1].to_numpy()\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.train_dataset,\n","            batch_size=self.config[\"batch_size\"],\n","            shuffle=True,\n","            **kwargs,\n","        )\n","\n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.validation_dataset,\n","            batch_size=self.config[\"batch_size\"],\n","            shuffle=False,\n","            **kwargs,\n","        )\n","\n","    def test_dataloader(self):\n","        return self.val_dataloader()\n","\n","    def predict_dataloader(self):\n","        return DataLoader(\n","            [image for image, _ in self.validation_dataset],\n","            batch_size=self.config[\"batch_size\"],\n","            shuffle=False,\n","            **kwargs,\n","        )\n","\n","\n","dm = DataModule(config, repo_path)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:45:00.536200Z","iopub.status.busy":"2022-03-07T11:45:00.535951Z","iopub.status.idle":"2022-03-07T11:45:12.336937Z","shell.execute_reply":"2022-03-07T11:45:12.327337Z","shell.execute_reply.started":"2022-03-07T11:45:00.536167Z"},"trusted":true},"outputs":[],"source":["dm.prepare_data()\n","dm.setup(stage=\"fit\")\n","first_batch = next(iter(dm.train_dataloader()))\n","\n","images, labels = first_batch[0], first_batch[1]\n","grid = utils.make_grid(images)\n","fig = plt.figure(figsize=(40, 10))\n","plt.imshow(grid.numpy().transpose((1, 2, 0)))\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Network definition"]},{"cell_type":"markdown","metadata":{},"source":["The next step is to define our model. This model is inspired by VGG11:\n","\n","* we define several convulational blocks.\n","* each of this block is sequence of:\n","  * convulational layer with `kernel_size=3, padding=1`\n","  * activation function, here it is the `ReLU`\n","  * max pooling layer with `kernel_size=2, stride=2` which aims at reducing the size of the convolutional layers"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:45:12.339548Z","iopub.status.busy":"2022-03-07T11:45:12.339069Z","iopub.status.idle":"2022-03-07T11:45:18.306393Z","shell.execute_reply":"2022-03-07T11:45:18.305689Z","shell.execute_reply.started":"2022-03-07T11:45:12.339502Z"},"trusted":true},"outputs":[],"source":["class PreTrainedVGG(models.BaseModel):\n","    def __init__(self, config, scaler=None):\n","        super().__init__(config)\n","\n","        self.config = config\n","        self.config[\"model_type\"] = type(self)\n","        self.scaler = scaler\n","\n","        self.configure_model()\n","        self.configure_criterion()\n","        self.configure_metrics()\n","\n","    def configure_model(self):\n","        assert self.config[\"total_layers\"] >= self.config[\"fixed_layers\"]\n","        vgg = pretrained_models.vgg16_bn(pretrained=True)\n","        self.layers = nn.Sequential(\n","            *(list(vgg.features.children())[: self.config[\"total_layers\"]])\n","        )\n","        for idx, child in enumerate(self.layers.children()):\n","            if idx < self.config[\"fixed_layers\"] and isinstance(child, nn.Conv2d):\n","                for param in child.parameters():\n","                    param.requires_grad = False\n","        #             else:\n","        #                 reset_parameters = getattr(child, \"reset_parameters\", None)\n","        #                 if callable(reset_parameters):\n","        #                     child.reset_parameters()\n","        nb_channels, width, a = (\n","            self.layers(\n","                torch.rand(\n","                    (1, 3, self.config[\"input_width\"], self.config[\"input_width\"])\n","                )\n","            )\n","            .squeeze()\n","            .shape\n","        )\n","\n","        input_fc = int(width ** 2 * nb_channels)\n","        # fully connected linear layers\n","        self.linear_layers = nn.Sequential(\n","            #             nn.BatchNorm2d(nb_channels),\n","            #             nn.ReLU(),\n","            #             nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Flatten(),\n","            nn.Linear(in_features=input_fc, out_features=512),\n","            nn.ReLU(),\n","            nn.Dropout2d(0.5),\n","            nn.Linear(in_features=512, out_features=512),\n","            nn.ReLU(),\n","            nn.Dropout2d(0.5),\n","            nn.Linear(in_features=512, out_features=23),\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        x = self.linear_layers(x)\n","        return x\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self(x)\n","        metrics = {name: metric(y, y_hat) for name, metric in self.metrics.items()}\n","        self.log_dict(metrics, on_step=False, on_epoch=True, prog_bar=True)\n","        return metrics\n","\n","\n","config[\"total_layers\"] = 44\n","config[\"fixed_layers\"] = 14\n","model = PreTrainedVGG(config)\n","print(model)\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"[INFO]: {total_params:,} total parameters.\")\n","model(torch.rand((1, 3, config[\"input_width\"], config[\"input_width\"])))\n"]},{"cell_type":"markdown","metadata":{},"source":["# Checkpoint\n","\n","We had 2 checkpoints to our training:\n","\n","* one for saving our model every time we have a minimum in the validation loss \n","* one for saving the model's and data module script"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:45:35.309418Z","iopub.status.busy":"2022-03-07T11:45:35.308868Z","iopub.status.idle":"2022-03-07T11:45:35.325524Z","shell.execute_reply":"2022-03-07T11:45:35.324711Z","shell.execute_reply.started":"2022-03-07T11:45:35.309383Z"},"trusted":true},"outputs":[],"source":["model_checkpoint = pl.callbacks.model_checkpoint.ModelCheckpoint(\n","    dirpath=run.dir if \"run\" in locals() else \"tmp/\",\n","    filename=\"{epoch}-{val_loss:.3f}\",\n","    monitor=\"val_loss\",\n","    mode=\"min\",\n","    verbose=True,\n","    save_last=True,\n",")\n","\n","script_checkpoint = training.ScriptCheckpoint(\n","    dirpath=run.dir if \"run\" in locals() else \"tmp/\",\n",")\n","\n","callbacks = [script_checkpoint]\n","log = None\n","if config[\"job_type\"] == \"train\" or True:\n","    callbacks.append(model_checkpoint)\n","    print(f\"[INFO]: saving models.\")\n","else:\n","    print(f\"[INFO]: not saving models.\")\n","if config[\"job_type\"] == \"debug\":\n","    log = \"all\"\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n","\n","We then train our model."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T11:45:45.394236Z","iopub.status.busy":"2022-03-07T11:45:45.393913Z","iopub.status.idle":"2022-03-07T14:09:04.409619Z","shell.execute_reply":"2022-03-07T14:09:04.408731Z","shell.execute_reply.started":"2022-03-07T11:45:45.394205Z"},"trusted":true},"outputs":[],"source":["if config[\"log_wandb\"]:\n","    wandb_logger = pl.loggers.WandbLogger()\n","    wandb_logger.watch(model, log=log, log_graph=True)\n","else:\n","    wandb_logger = None\n","trainer = pl.Trainer(\n","    max_epochs=250,\n","    callbacks=callbacks,\n","    logger=wandb_logger,\n","    devices=\"auto\",\n","    accelerator=\"auto\",\n","    limit_train_batches=0.3,\n","    #     limit_val_batches=1,\n","    #     log_every_n_steps=1,\n",")\n","trainer.fit(\n","    model,\n","    datamodule=dm,\n",")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T14:09:08.209449Z","iopub.status.busy":"2022-03-07T14:09:08.209141Z","iopub.status.idle":"2022-03-07T14:09:46.012880Z","shell.execute_reply":"2022-03-07T14:09:46.012021Z","shell.execute_reply.started":"2022-03-07T14:09:08.209419Z"},"trusted":true},"outputs":[],"source":["dm.prepare_data()\n","dm.setup(\"validate\")\n","predictions = torch.cat(trainer.predict(model, dataloaders=dm.predict_dataloader()))\n","targets = torch.FloatTensor(dm.targets)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T14:09:46.015461Z","iopub.status.busy":"2022-03-07T14:09:46.014746Z","iopub.status.idle":"2022-03-07T14:09:46.639057Z","shell.execute_reply":"2022-03-07T14:09:46.638324Z","shell.execute_reply.started":"2022-03-07T14:09:46.015422Z"},"trusted":true},"outputs":[],"source":["save_output = training.SaveOutput()\n","handle = model.layers[3].register_forward_hook(save_output)\n","image = images[0]\n","model(image.unsqueeze(0))\n","handle.remove()\n","outputs = save_output.outputs[0].permute(1, 0, 2, 3).detach().cpu()[:30]\n","grid_img = utils.make_grid(outputs, normalize=True, pad_value=1, padding=1)\n","plt.figure(figsize=(30, 30))\n","plt.imshow(grid_img.permute(1, 2, 0))\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T14:12:17.325386Z","iopub.status.busy":"2022-03-07T14:12:17.324970Z","iopub.status.idle":"2022-03-07T14:12:22.785224Z","shell.execute_reply":"2022-03-07T14:12:22.784572Z","shell.execute_reply.started":"2022-03-07T14:12:17.325351Z"},"trusted":true},"outputs":[],"source":["fig = plotting.plot_kde(\n","    [targets.cpu().numpy(), dm.scaler.inverse_transform(predictions.cpu().numpy())],\n","    nb_hist_per_line=6,\n","    columns=dm.train_df.columns[1:-1],\n",")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T14:12:47.713668Z","iopub.status.busy":"2022-03-07T14:12:47.713371Z","iopub.status.idle":"2022-03-07T14:12:53.614588Z","shell.execute_reply":"2022-03-07T14:12:53.613714Z","shell.execute_reply.started":"2022-03-07T14:12:47.713619Z"},"trusted":true},"outputs":[],"source":["run.finish()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
